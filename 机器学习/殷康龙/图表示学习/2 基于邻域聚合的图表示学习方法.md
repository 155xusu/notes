# 基于邻域聚合的图表示学习方法




## 概念

基于邻域聚合的图表示学习方法通过聚合本地邻居节点的信息得到当前节点的嵌入表示，该方法与计算机视觉领域中的“卷积”操作类似，因此基于邻域聚合的图表示学习方法也被称为基于卷积的图表示学习方法。基于邻域聚合的图表示学习方法过程如下所示，包括三个步骤：


```
输入：𝐺(𝑉, 𝐸, 𝑥); W𝑡, ∀𝑡 𝜖 [1, 𝑇]
输出：节点嵌入表示𝑧𝜈, ∀𝜈 𝜖 𝑉
初始化 ℎ𝜈0 ← 𝑥𝜈, ∀𝜈 𝜖 𝑉
for 𝑡 = 1 to 𝑇 do
 for 𝜈 𝜖 𝑉 do
 ℎ𝑁(𝜈) 𝑡 ← AGGREGATE𝑡({ℎ𝑢𝑡−1, ∀𝑢 𝜖 𝑁(𝜈)})
 ℎ𝜈𝑡 ← 𝜎 (W𝑡 ∙ COMBINE(ℎ𝜈𝑡−1, ℎ𝑁(𝜈) 𝑡 ))
 end
 ℎ𝜈𝑡 ← NORMALIZE(ℎ𝜈𝑡 , ∀𝜈 𝜖 𝑉)
end
𝑧𝜈 ← ℎ𝜈𝑇, ∀𝜈 𝜖 𝑉
```
1. 信息发送。节点𝜈将自身的特征信息进行抽取变换，并发送给邻居节点𝑁(𝜈)。在初始时刻，节点𝜈的自身特征信息ℎ𝜈𝑘即为传入的节点特征𝑥𝜈；在接下来的时刻，节点的特征信息会随着每一轮信息聚合过程而发生改变。
2. 信息聚合。节点𝜈通过信息聚合函数将邻域范围内的邻居节点的特征信息{$ℎ_𝑢^{𝑡−1}$, ∀𝑢 𝜖 𝑁(𝜈)}聚合起来，从而实现邻域内的结构信息融合。
3. 信息变换。节点𝜈将上个时刻的节点特征ℎ𝜈𝑡−1与当前聚合到的邻居节点特征 $ℎ_{𝑁(v)}^t$结合，并进行非线性变换。

## 算法

基于邻域聚合的思路，研究者们提出了大量的图表示学习算法，如图卷积神经网络算法（GCN）[52]、GraphSAGE 算法[51]等，这些算法之间的主要区别在于信息聚合与信息变换所采用的方法不同，如 GraphSAGE 设计了通用的聚合函数框架，支持均值聚合、最大池化聚合与 LSTM 聚合等方法，并采用了特征向量拼接的方式进行信息变换；GCN 则设计了带权均值聚合函数，并采用了加权求和的方式进行信息变换，但是由于 GCN 依赖于矩阵分解运算，因此 GCN 并不具备和其它基于邻域聚合思路的图表示学习算法的同等程度的泛化能力，一旦网络中有新的节点出现，就必须重新训练模型得到新节点的嵌入表示。