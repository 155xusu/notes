## 任务



* [X] 四月份计划——tensorflow federated
* [X] 四月份计划——pytorch——pysyft

  * [x] 官方教程
  * [x] 相关博客实践

  * [x] 学弟的代码
  * [x] 自己实现


* [ ] 四月份计划——pytorch——basic教程（整理完教程，API文档layer、loss、optimizer整理完成，看视频吧）
* [x] ~~四月份计划——pytorch——分布式教程(包括教程和API文章整理)~~

* [x] ~~四月份计划——pytorch——android教程（包括教程和API文章整理）~~
* [x] 四月份计划——pytorch——APIdoc

## 收获

1. 我发现python机器学习这一套在linux下更好运行，windows配置环境果然要麻烦一百倍。从今天开始将主要的工作环境转移到linux上边。算法的运行和学习都在linux上执行。去Windows上做一下收尾工作。
2. 当前的主要任务包括两个，一个是四月份未完成的计划。一个是五月份新开始的计划。
3. tensorflow federated已经学习完成了，能够完成基本的联邦学习过程。因为与学弟合作的部分还是pytorch。今后最好使用pytorch进行开发吧。除非由绝对的优势，不会回到tensorflow上了。
4. 学习了很多新的Python知识、掌握了pysyft框架的基本使用方法和一系列原理。主要目标有两个：**使用、修改**。

   1. Python的模块loggin、asynicio、argparse等、第三方模块websocket，
   2. pysyft的原理。worker通信原理和websocket实现（send、receive、client、server）、远程计算的实现（plan，protocol）、加密算法的实现（MFC同态加密）、联邦平均算法的实现（util.fed_avg(models))
   3. pytorch的模块的使用。torch.nn,torch.function,torch.jit(实现了代码的序列化)
5. 从周一拖到现在，本来应该是上周的计划，到现在刚做完。问题就是，为什么random.shuffle效率会提升？？？？？？？太离谱了。总算是完成第一阶段集中式的问题了。今天怎么也得完成5月6号的任务。
