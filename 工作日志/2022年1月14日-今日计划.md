## 任务

* [ ] 数据同步已经开启



## 收获

* 周三晚上开始到周五晚上整整两天时间，解决了台式机的性能问题和数据传输问题。
* 因为台式机的性能导致特征提取过程十分缓慢，甚至单线程解析的时候，都会直接导致cpu爆炸，所以寻求性能更好的主机用来提取最基础的特征，所以选择了高性能计算中心的台式机。花了一晚上时间学习了高性能计算中心的使用教程。
* 为了将本地的数据集同步到云端，想了各种各样的方法。
  * 由于实验室ip封禁问题，导致没办法使用实验的的ip地址登录高性能计算中心，所以研究了笔记本双网卡的建设，通过route add/route print/route delete 等命令，设置了双网卡路由，使得10.网段的路由经过无线网卡访问外网，能够在笔记本上访问高性能计算中心。
  * 为了加快数据传输，使用了新的学校内网网口，买了网线，在李师姐的电脑上进行数据传输。学习了scp命令，使用scp实现两个主机文件夹的远程对拷，发现进度十分缓慢，只有几兆，可能要拷贝好几天。学习了xftp拖拽式上传，速度是挺快，传完了drebin数据集的几个安装包，但是因为androzoo文件量太多，导致软件经常崩溃，没办法通过xftp实现远程同步传输。而且xftp本身提供很强的远程同步功能，但是因为缺少压缩，文件数量过多，软件不稳定等原因，传输一直失败。但是总算通过解压drebin安装包的方式完成了drebin数据集的远程同步。
  * 思考了一个问题，既然传输速度只有10M左右，还不如直接自己在本地开30个线程直接下载的速度快，所以花了一晚上加一早上，重新写了文件androzoo_downloader模块，包括直接开始30个进程进行下载，并且能够递归访问目录，跳过重复的文件，避免重复下载等功能。并将下载脚本规范为自己常用的Python脚本，企图在高性能计算中心的服务器上直接下载文件，但是最后发现，高性能计算中心的网卡提供了高额的对内传输速度，但是对外网的传输速度惨不忍睹，可能也只有三四兆左右，下载一晚上，就下载了一小部分。
  * 在重写androzoo_downloader模块的时候，考虑使用高性能计算中心的cpu节点进行计算任务，也不是cpu密集型，而且用到了30个线程，第一次完成了sbatch cpu任务的提交。发现计算节点没有网卡，不具有下载连接的功能，导致下载失败。学习了sbatch的配置和命令执行，以及查看配置的命令smcat等，可以显示运行状态，还可以将日志输送到指定的位置。
  * 至此有点心灰意冷。将硬盘从师姐那取回来，欲接受无法快速传输完成并完成文件特征提取的任务，开始考虑两边同时工作，让台式机慢慢传输文件，然后在台式机上进行本地的开发、代码阅读、论文阅读等任务。但是台式机又不能传输（公网ip被禁），笔记本能通过无线网络传输，但是没办法进行开发（windows环境没配置好），但硬盘数据只有一份，彻底没办法。
  * 最后突然想起来通过校园网认证界面能够看到登录ip地址，然后下午学弟说解封ip地址非常简单，然后睡觉的功夫就解封的ip地址。就可以将硬盘连接到台式机上，用台式机传输数据并且用台式机完成开发工作。但是仍然缺少一个文件传输的工具，像xftp的远程同步功能，能够跳过已经传输的文件，实现断点续传。至此发现了rsync远程同步工具，能够快速压缩传输，并且，远程同步过程中，能够跳过已经传输的文件，传输速度非常可观。通过开始10个窗口命令行，完成了远程的同步传输。如果出了问题还可以重新运行命令，继续之前的传输功能，发现非常好用！！！！！！！linux下好用的工具和命令果然非常多。
  * 接下来要做的就是在数据传输过程中，读论文，看代码。补充后续的特征分析方法、特征嵌入方法、神经网络的基础知识，在传输完成，运行特征提取任务的同时，完后学习任务。然后接着进行后续的步骤！！！！！！！然后下周开始写图特征提取和分析的相关脚本。