{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd05ef0042cb263260037aa2928643ae94e240dd3afaec7872ebebe4f07619ddd0c",
   "display_name": "Python 3.8.8 64-bit ('ml': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://storage.googleapis.com/tff-datasets-public/fed_emnist_digitsonly.tar.bz2\n",
      "97402880/97398400 [==============================] - 6s 0us/step\n",
      "WARNING:tensorflow:AutoGraph could not transform <function client_data.<locals>.<lambda> at 0x0000016F610DF820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function client_data.<locals>.<lambda> at 0x0000016F610DF820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function client_data.<locals>.<lambda> at 0x0000016F610DD940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function client_data.<locals>.<lambda> at 0x0000016F610DD940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function client_data.<locals>.<lambda> at 0x0000016F6231CB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function client_data.<locals>.<lambda> at 0x0000016F6231CB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "from_keras_model() got an unexpected keyword argument 'dummy_batch'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-48f9e54d058c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# Simulate a few rounds of training with the selected client devices.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m trainer = tff.learning.build_federated_averaging_process(\n\u001b[0m\u001b[0;32m     32\u001b[0m   \u001b[0mmodel_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m   client_optimizer_fn=lambda: tf.keras.optimizers.SGD(0.1))\n",
      "\u001b[1;32mD:\\anaconda\\envs\\ml\\lib\\site-packages\\tensorflow_federated\\python\\learning\\federated_averaging.py\u001b[0m in \u001b[0;36mbuild_federated_averaging_process\u001b[1;34m(model_fn, client_optimizer_fn, server_optimizer_fn, client_weight_fn, broadcast_process, aggregation_process, model_update_aggregation_factory, use_experimental_simulation_loop)\u001b[0m\n\u001b[0;32m    221\u001b[0m                         use_experimental_simulation_loop)\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m   return optimizer_utils.build_model_delta_optimizer_process(\n\u001b[0m\u001b[0;32m    224\u001b[0m       \u001b[0mmodel_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[0mmodel_to_client_delta_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclient_fed_avg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\ml\\lib\\site-packages\\tensorflow_federated\\python\\learning\\framework\\optimizer_utils.py\u001b[0m in \u001b[0;36mbuild_model_delta_optimizer_process\u001b[1;34m(model_fn, model_to_client_delta_fn, server_optimizer_fn, broadcast_process, aggregation_process, model_update_aggregation_factory)\u001b[0m\n\u001b[0;32m    608\u001b[0m   \u001b[0mpy_typecheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserver_optimizer_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m   \u001b[0mmodel_weights_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights_type_from_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mbroadcast_process\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\ml\\lib\\site-packages\\tensorflow_federated\\python\\learning\\model_utils.py\u001b[0m in \u001b[0;36mweights_type_from_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;31m# with variables created for this model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m       \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m   \u001b[0mpy_typecheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtype_conversions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_from_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModelWeights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-48f9e54d058c>\u001b[0m in \u001b[0;36mmodel_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m                             kernel_initializer='zeros')\n\u001b[0;32m     23\u001b[0m   ])\n\u001b[1;32m---> 24\u001b[1;33m   return tff.learning.from_keras_model(\n\u001b[0m\u001b[0;32m     25\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m       \u001b[0mdummy_batch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: from_keras_model() got an unexpected keyword argument 'dummy_batch'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "# Load simulation data.\n",
    "source, _ = tff.simulation.datasets.emnist.load_data()\n",
    "def client_data(n):\n",
    "  return source.create_tf_dataset_for_client(source.client_ids[n]).map(\n",
    "      lambda e: (tf.reshape(e['pixels'], [-1]), e['label'])\n",
    "  ).repeat(10).batch(20)\n",
    "\n",
    "# Pick a subset of client devices to participate in training.\n",
    "train_data = [client_data(n) for n in range(3)]\n",
    "\n",
    "# Grab a single batch of data so that TFF knows what data looks like.\n",
    "sample_batch = tf.nest.map_structure(\n",
    "    lambda x: x.numpy(), iter(train_data[0]).next())\n",
    "\n",
    "# Wrap a Keras model for use with TFF.\n",
    "def model_fn():\n",
    "  model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(10, tf.nn.softmax, input_shape=(784,),\n",
    "                            kernel_initializer='zeros')\n",
    "  ])\n",
    "  return tff.learning.from_keras_model(\n",
    "      model,\n",
    "      dummy_batch=sample_batch,\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "# Simulate a few rounds of training with the selected client devices.\n",
    "trainer = tff.learning.build_federated_averaging_process(\n",
    "  model_fn,\n",
    "  client_optimizer_fn=lambda: tf.keras.optimizers.SGD(0.1))\n",
    "state = trainer.initialize()\n",
    "for _ in range(5):\n",
    "  state, metrics = trainer.next(state, train_data)\n",
    "  print (metrics.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}